{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'GlorotUniform' from 'keras.initializers' (/home/aniket/anaconda3/lib/python3.7/site-packages/keras/initializers.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-aa14af8b88f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGlorotUniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_eager_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'GlorotUniform' from 'keras.initializers' (/home/aniket/anaconda3/lib/python3.7/site-packages/keras/initializers.py)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.initializers import GlorotUniform\n",
    "tf.enable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras==2.2.4 in /home/aniket/anaconda3/lib/python3.7/site-packages (2.2.4)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/aniket/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (1.17.2)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/aniket/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (1.3.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/aniket/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (1.12.0)\n",
      "Requirement already satisfied: pyyaml in /home/aniket/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (5.1.2)\n",
      "Requirement already satisfied: h5py in /home/aniket/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (2.9.0)\n",
      "Requirement already satisfied: keras_applications>=1.0.6 in /home/aniket/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (1.0.8)\n",
      "Requirement already satisfied: keras_preprocessing>=1.0.5 in /home/aniket/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install keras==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqr(var1):\n",
    "    return tf.math.square(var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha = tf.Variable(1.0)\n",
    "beta = tf.Variable(1.0)\n",
    "phi = tf.Variable(1.0)\n",
    "theta = tf.Variable(1.0)\n",
    "gamma = tf.Variable(1.0)\n",
    "r = tf.Variable(1)\n",
    "t = tf.Variable(1)\n",
    "rl = tf.Variable(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = tf.Variable(1/3)\n",
    "c2 = tf.Variable(2/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sin_alpha = tf.math.sin(alpha)\n",
    "sin_two_alpha = tf.math.sin(2*alpha)\n",
    "sin_beta = tf.math.sin(beta)\n",
    "sin_two_beta = tf.math.sin(2*beta)\n",
    "sin_phi = tf.math.sin(phi)\n",
    "sin_two_phi = tf.math.sin(2*phi)\n",
    "sin_theta = tf.math.sin(theta)\n",
    "sin_two_theta = tf.math.sin(2*theta)\n",
    "sin_gamma = tf.math.sin(gamma)\n",
    "sin_phi_beta_subt = tf.math.sin(phi - beta)\n",
    "\n",
    "\n",
    "cos_alpha = tf.math.cos(alpha)\n",
    "cos_beta = tf.math.cos(beta)\n",
    "cos_two_beta = tf.math.cos(2*beta)\n",
    "cos_phi = tf.math.cos(phi)\n",
    "cos_two_phi = tf.math.cos(2*phi)\n",
    "cos_theta = tf.math.cos(theta)\n",
    "cos_gamma = tf.math.cos(gamma)\n",
    "cos_beta_phi_subt = tf.math.cos(beta - phi)\n",
    "cos_beta_theta_add = tf.math.cos(beta + theta)\n",
    "\n",
    "cosec_theta = tf.math.acos(theta)\n",
    "cot_theta = tf.math.atan(theta)\n",
    "cot_alpha = tf.math.atan(alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z1 = sqr(sin_alpha)*sqr(sin_theta)*sqr(cos_beta_phi_subt) + sin_two_theta*sin_alpha*cos_beta_phi_subt - c1\n",
    "\n",
    "Z2 = sqr(sin_alpha)*sqr(cos_theta)*sqr(cos_beta_phi_subt) - sin_alpha*cos_alpha*sin_two_theta*cos_beta_phi_subt + sqr(cos_alpha)*sqr(sin_theta) - c1\n",
    "\n",
    "Z3 = sqr(sin_alpha)*sqr(cosec_theta)*sqr(sin_phi_beta_subt) - c1\n",
    "\n",
    "Z4 = sin_two_theta\n",
    "\n",
    "Z5 = sqr(sin_alpha)*sin_two_phi + sqr(cos_alpha)*sin_two_theta + sin_two_beta*sqr(sin_alpha)*cos_two_phi + sin_two_alpha*cot_theta*(cos_beta*sin_phi + sin_beta*cos_phi)\n",
    "\n",
    "Z6 = sqr(sin_alpha)*cot_theta*(cos_beta*sin_beta*cos_two_phi - sqr(cos_beta)*sin_two_phi) + sqr(sin_alpha)*sin_phi_beta_subt\n",
    "\n",
    "Z7 = sqr(sin_alpha)*(sqr(cos_theta)*sqr(cos_beta_theta_add) + sqr(cos_beta*sin_phi + sin_beta) -sqr(sin_beta)*sqr(sin_phi)  + sqr(cos_alpha)*sqr(sin_theta) - c2  )\n",
    "\n",
    "Z8 = sqr(cos_beta)*sqr(sin_alpha)\n",
    "\n",
    "Z9 = sqr(sin_alpha) * ( sin_beta*cos_beta*(sqr(cosec_theta)*cos_two_phi + cosec_theta*cot_theta + cos_two_phi) + sin_beta*cot_alpha*cot_theta*cos_phi - sin_phi*cos_phi*cos_two_beta*cot_theta*(cot_theta - cosec_theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_net = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(8,)),\n",
    "    tf.keras.layers.Dense(124, activation = tf.nn.relu),\n",
    "    tf.keras.layers.Dense(1, activation = tf.nn.sigmoid)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def u(t, r, alpha, beta, theta, phi, gamma, rl):\n",
    "    u = neural_net([t, r, alpha, beta, theta, phi, gamma, rl], weights, biases)\n",
    "    return u    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(u):\n",
    "    u_t = tf.gradients(u, t)[0]\n",
    "    u_r = tf.gradients(u, r)[0]\n",
    "    u_rr = tf.gradients(u_r, r)[0]\n",
    "    u_sq_rr = tf.gradients(sqr(r)*u_r, r)[0]\n",
    "    \n",
    "    u_th = tf.gradients(u, theta)[0]\n",
    "    u_th = tf.gradients(u_th, theta)[0]\n",
    "    u_th_sin = tf.gradients(tf.math.sin(theta)*u_th, theta)[0]\n",
    "    u_th_r = tf.gradients(u_th, r)[0]\n",
    "    u_th_ph = tf.gradients(u_th, phi)[0]\n",
    "    \n",
    "    u_ph = tf.gradients(u, phi)[0]\n",
    "    u_phph = tf.gradients(u_ph, phi)[0]\n",
    "    u_ph_r = tf.gradients(u_ph, r)[0]\n",
    "    \n",
    "    term1 = (1/sqr(r))*(u_sq_rr)\n",
    "    term2 = (1/sqr(r*sin_theta))*u_th_sin\n",
    "    term3 = (1/sqr(r*sin_theta))*u_phph\n",
    "    del_sqr_spherical = term1 + term2 + term3\n",
    "    \n",
    "    Z = Z1*u_rr + (1/sqr(r))*(Z2*u_thth + Z3*u_phph + Z4*u_th_r - Z5*u_ph_r - Z6*u_th_ph + Z8*u_th + Z9*u_phi)+(1/r)*Z7*u_r\n",
    "    f = u_t - del_sqr_spherical - Z               \n",
    "    return f               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(u):\n",
    "    u_t = tf.gradients(u, t)[0]\n",
    "    u_r = tf.gradients(u, r)[0]\n",
    "    u_rr = tf.gradients(u_r, r)[0]\n",
    "    u_sq_rr = tf.gradients(sqr(r)*u_r, r)[0]\n",
    "    \n",
    "    u_th = tf.gradients(u, theta)[0]\n",
    "    u_th = tf.gradients(u_th, theta)[0]\n",
    "    u_th_sin = tf.gradients(tf.math.sin(theta)*u_th, theta)[0]\n",
    "    u_th_r = tf.gradients(u_th, r)[0]\n",
    "    u_th_ph = tf.gradients(u_th, phi)[0]\n",
    "    \n",
    "    u_ph = tf.gradients(u, phi)[0]\n",
    "    u_phph = tf.gradients(u_ph, phi)[0]\n",
    "    u_ph_r = tf.gradients(u_ph, r)[0]\n",
    "    \n",
    "    term1 = (1/sqr(r))*(u_sq_rr)\n",
    "    term2 = (1/sqr(r*sin_theta))*u_th_sin\n",
    "    term3 = (1/sqr(r*sin_theta))*u_phph\n",
    "    del_sqr_spherical = term1 + term2 + term3\n",
    "    \n",
    "    Z = Z1*u_rr + (1/sqr(r))*(Z2*u_thth + Z3*u_phph + Z4*u_th_r - Z5*u_ph_r - Z6*u_th_ph + Z8*u_th + Z9*u_phi)+(1/r)*Z7*u_r\n",
    "    f = u_t - del_sqr_spherical - Z               \n",
    "    return f               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class model:\n",
    "    \n",
    "    def __init__(self):\n",
    "        xavier=tf.keras.initializers.GlorotUniform()\n",
    "        self.l1=tf.keras.layers.Dense(64,kernel_initializer=xavier,activation=tf.nn.relu,input_shape=[1])\n",
    "        self.l2=tf.keras.layers.Dense(64,kernel_initializer=xavier,activation=tf.nn.relu)\n",
    "        self.out=tf.keras.layers.Dense(1,kernel_initializer=xavier)\n",
    "        self.train_op = tf.keras.optimizers.Adagrad(learning_rate=0.1)\n",
    "        \n",
    "    # Running the model\n",
    "    def run(self,X):\n",
    "        boom=self.l1(X)\n",
    "        boom1=self.l2(boom)\n",
    "        boom2=self.out(boom1)\n",
    "        return boom2\n",
    "      \n",
    "    #Custom loss fucntion\n",
    "    def get_loss(self,X,Y):\n",
    "        boom=self.l1(X)\n",
    "        boom1=self.l2(boom)\n",
    "        boom2=self.out(boom1)\n",
    "        return f(boom2)\n",
    "      \n",
    "    # get gradients\n",
    "    def get_grad(self,X,Y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(self.l1.variables)\n",
    "            tape.watch(self.l2.variables)\n",
    "            tape.watch(self.out.variables)\n",
    "            L = self.get_loss(X,Y)\n",
    "            g = tape.gradient(L, [self.l1.variables[0],self.l1.variables[1],self.l2.variables[0],self.l2.variables[1],self.out.variables[0],self.out.variables[1]])\n",
    "        return g\n",
    "      \n",
    "    # perform gradient descent\n",
    "    def network_learn(self,X,Y):\n",
    "        g = self.get_grad(X,Y)\n",
    "        self.train_op.apply_gradients(zip(g, [self.l1.variables[0],self.l1.variables[1],self.l2.variables[0],self.l2.variables[1],self.out.variables[0],self.out.variables[1]]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(8,1)\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(8, activation=tf.nn.sigmoid, input_shape=input_shape),  # input shape required\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.sigmoid),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = tf.Variable(np.random.normal(size=(1,8,1)), dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    preds = model(inp)\n",
    "\n",
    "grads = tape.gradient(preds, inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.16502717323601246, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array([1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\n",
    "#inputs = tf.reshape(inputs,[1,8,1])\n",
    "#inputs = tf.Variable(inputs)\n",
    "#inputs = tf.cast(inputs,tf.float32)\n",
    "t = tf.Variable(inputs[0])\n",
    "r = tf.Variable(inputs[1])\n",
    "alpha= tf.Variable(inputs[2])\n",
    "beta= tf.Variable(inputs[3])\n",
    "theta= tf.Variable(inputs[4])\n",
    "phi= tf.Variable(inputs[5])\n",
    "gamma= tf.Variable(inputs[6])\n",
    "rl= tf.Variable(inputs[7])\n",
    "\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape2:\n",
    "    with tf.GradientTape(persistent=True) as tape1:\n",
    "        inp = tf.reshape(tf.stack([t, r, alpha, beta, theta, phi, gamma, rl]),[1,8,1])\n",
    "        inp = tf.cast(inp,tf.float32)\n",
    "        tape1.watch([t, r, alpha, beta, theta, phi, gamma, rl])\n",
    "        preds = model(inp)\n",
    "    d_t,d_r,d_al,d_bt,d_th,d_ph,d_gm,d_rl = tape1.gradient(preds, [t, r, alpha, beta, theta, phi, gamma, rl])\n",
    "d_r_r = tape2.gradient(d_r, r)\n",
    "d_th_r = tape2.gradient(d_th, r)\n",
    "d_th_ph = tape2.gradient(d_th, phi)\n",
    "d_th_th = tape2.gradient(d_th, theta)\n",
    "d_ph_ph = tape2.gradient(d_ph, phi)\n",
    "#d_sq_r_r = tape2.gradient(sqr(r)*d_r, r)\n",
    "d_sq_r_r = 2*r*d_r + sqr(r)*d_r_r\n",
    "d_th_sin = tf.math.cos(theta)*d_th + tf.math.sin(theta)*d_th_th\n",
    "\n",
    "print (d_sq_r_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(d_t_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "x_size = [1000,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1000, 8]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = tf.random.uniform(shape=x_size, dtype=tf.dtypes.float32, seed=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tf.random.uniform(shape=[num_samples], dtype=tf.dtypes.float32, seed=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tuple(zip(points, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(model, inputs, targets):\n",
    "    t = tf.Variable(inputs[0])\n",
    "    r = tf.Variable(inputs[1])\n",
    "    alpha= tf.Variable(inputs[2])\n",
    "    beta= tf.Variable(inputs[3])\n",
    "    theta= tf.Variable(inputs[4])\n",
    "    phi= tf.Variable(inputs[5])\n",
    "    gamma= tf.Variable(inputs[6])\n",
    "    rl= tf.Variable(inputs[7])\n",
    "    with tf.GradientTape(persistent=True) as tape2:\n",
    "        tape2.watch(model.trainable_variables)\n",
    "        print (\"tape2: \",tape2.watched_variables())\n",
    "        with tf.GradientTape(persistent=True) as tape1:\n",
    "            inp = tf.reshape(tf.stack([t, r, alpha, beta, theta, phi, gamma, rl]),[1,8,1])\n",
    "            inp = tf.cast(inp,tf.float32)\n",
    "            tape1.watch([t, r, alpha, beta, theta, phi, gamma, rl])\n",
    "            preds = model(inp)\n",
    "        d_t,d_r,d_al,d_bt,d_th,d_ph,d_gm,d_rl = tape1.gradient(tf.convert_to_tensor(preds), [t, r, alpha, beta, theta, phi, gamma, rl])\n",
    "    d_r_r = tape2.gradient(d_r, r)\n",
    "    #d_sq_r_r = tape2.gradient(sqr(r)*d_r, r)\n",
    "    #d_th_sin = tape2.gradient(tf.math.sin(theta)*d_th, theta)\n",
    "    d_th_r = tape2.gradient(d_th, r)\n",
    "    d_th_ph = tape2.gradient(d_th, phi)\n",
    "    d_th_th = tape2.gradient(d_th, theta)\n",
    "    d_ph_ph = tape2.gradient(d_ph, phi)\n",
    "    d_ph_r = tape2.gradient(d_ph, r)\n",
    "    d_sq_r_r = 2*r*d_r + sqr(r)*d_r_r\n",
    "    d_th_sin = tf.math.cos(theta)*d_th + tf.math.sin(theta)*d_th_th\n",
    "    term1 = (1/sqr(r))*(d_sq_r_r)\n",
    "    term2 = (1/sqr(r*sin_theta))*d_th_sin\n",
    "    term3 = (1/sqr(r*sin_theta))*d_ph_ph\n",
    "    del_sqr_spherical = term1 + term2 + term3\n",
    "    Z = Z1*d_r_r + (1/sqr(r))*(Z2*d_th_th + Z3*d_ph_ph + Z4*d_th_r - Z5*d_ph_r - Z6*d_th_ph + Z8*d_th + Z9*d_ph)+(1/r)*Z7*d_r\n",
    "    loss_value = d_t - del_sqr_spherical - Z\n",
    "    gradients = tape1.gradient(loss_value, model.trainable_variables)\n",
    "    return loss_value,gradients\n",
    "            \n",
    "            \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tape2:  (<tf.Variable 'dense_20/kernel:0' shape=(1, 8) dtype=float32, numpy=\n",
      "array([[ 0.42560804, -0.49918646, -0.81160265, -0.3933895 ,  0.49500656,\n",
      "         0.37414932, -0.17501348, -0.642167  ]], dtype=float32)>, <tf.Variable 'dense_20/bias:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'dense_21/kernel:0' shape=(8, 10) dtype=float32, numpy=\n",
      "array([[ 0.1892454 , -0.10135975, -0.15481803, -0.00485963,  0.2971394 ,\n",
      "         0.53685427,  0.2051273 ,  0.5624374 ,  0.44773102,  0.43416584],\n",
      "       [ 0.282642  ,  0.16845226, -0.2444835 , -0.50393283, -0.5321783 ,\n",
      "         0.2640378 , -0.28939545, -0.28365308, -0.02669412, -0.5646726 ],\n",
      "       [-0.06311864, -0.05427784,  0.2259748 , -0.07778975,  0.47075772,\n",
      "         0.00684357, -0.27885842,  0.33664292,  0.12761873, -0.5046518 ],\n",
      "       [-0.39418727, -0.27024433,  0.43482256, -0.05637485, -0.4229043 ,\n",
      "         0.0282647 ,  0.18885309, -0.4634096 ,  0.02956426,  0.4779271 ],\n",
      "       [ 0.05967516, -0.06307942, -0.55015606, -0.02913344, -0.54683274,\n",
      "         0.4797697 ,  0.09196919,  0.11756235,  0.4578222 ,  0.06672853],\n",
      "       [-0.46310884,  0.5201458 , -0.2608615 , -0.03875333,  0.01835716,\n",
      "        -0.21572903, -0.42027915,  0.54264927, -0.31016782,  0.04753822],\n",
      "       [-0.1862351 ,  0.22949195, -0.22351265,  0.46414304, -0.5590855 ,\n",
      "         0.37690008,  0.2968037 , -0.54572326, -0.15523526, -0.51390165],\n",
      "       [-0.2962619 , -0.4812507 ,  0.55508125, -0.24664298,  0.4574741 ,\n",
      "        -0.14284873,  0.38597584,  0.12117708, -0.4195298 ,  0.20419306]],\n",
      "      dtype=float32)>, <tf.Variable 'dense_21/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'dense_22/kernel:0' shape=(10, 1) dtype=float32, numpy=\n",
      "array([[ 0.65677303],\n",
      "       [-0.14957279],\n",
      "       [-0.49738652],\n",
      "       [ 0.28225082],\n",
      "       [ 0.6951547 ],\n",
      "       [-0.36333057],\n",
      "       [-0.29871964],\n",
      "       [ 0.5894957 ],\n",
      "       [ 0.5559661 ],\n",
      "       [ 0.6367757 ]], dtype=float32)>, <tf.Variable 'dense_22/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable: ['dense_20/kernel:0', 'dense_20/bias:0', 'dense_21/kernel:0', 'dense_21/bias:0', 'dense_22/kernel:0', 'dense_22/bias:0'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-221-641e0e57887b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Optimize the model1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Track progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mepoch_loss_avg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    423\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mnone\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvariables\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \"\"\"\n\u001b[0;32m--> 425\u001b[0;31m     \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_filter_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_filter_grads\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m   1021\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m     raise ValueError(\"No gradients provided for any variable: %s.\" %\n\u001b[0;32m-> 1023\u001b[0;31m                      ([v.name for _, v in grads_and_vars],))\n\u001b[0m\u001b[1;32m   1024\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvars_with_empty_grads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m     logging.warning(\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: ['dense_20/kernel:0', 'dense_20/bias:0', 'dense_21/kernel:0', 'dense_21/bias:0', 'dense_22/kernel:0', 'dense_22/bias:0']."
     ]
    }
   ],
   "source": [
    "## Note: Rerunning this cell uses the same model variables\n",
    "\n",
    "# Keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 201\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "      epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "      epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "\n",
    "  # Training loop - using batches of 32\n",
    "      for x, y in train_dataset:\n",
    "        # Optimize the model1) \n",
    "        loss_value, grads = grad(model, x, y)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        # Track progress\n",
    "        epoch_loss_avg(loss_value)\n",
    "        \n",
    "        # Add current batch loss\n",
    "        # Compare predicted label to actual label\n",
    "        # training=True is needed only if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        epoch_accuracy(y, model(x, training=True))\n",
    "        \n",
    "        # End epoch\n",
    "        train_loss_results.append(epoch_loss_avg.result())\n",
    "        train_accuracy_results.append(epoch_accuracy.result())\n",
    "\n",
    "        if epoch % 50 == 0:\n",
    "            print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
    "                                                                    epoch_loss_avg.result()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.compile(optimizer = 'adam', loss = custom_loss, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[1,2,3,4,5,6,7,8,9,10]\n",
    "x=np.asarray(x,dtype=np.float32).reshape((10,1))\n",
    "y=[1,4,9,16,25,36,49,64,81,100]\n",
    "y=np.asarray(y,dtype=np.float32).reshape((10,1))\n",
    "model=model()\n",
    "for i in range(100):\n",
    "    model.network_learn(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
