{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'GlorotUniform' from 'keras.initializers' (/home/aniket/anaconda3/lib/python3.7/site-packages/keras/initializers.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-aa14af8b88f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGlorotUniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_eager_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'GlorotUniform' from 'keras.initializers' (/home/aniket/anaconda3/lib/python3.7/site-packages/keras/initializers.py)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.initializers import GlorotUniform\n",
    "tf.enable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras==2.2.4 in /home/aniket/anaconda3/lib/python3.7/site-packages (2.2.4)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/aniket/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (1.17.2)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/aniket/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (1.3.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/aniket/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (1.12.0)\n",
      "Requirement already satisfied: pyyaml in /home/aniket/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (5.1.2)\n",
      "Requirement already satisfied: h5py in /home/aniket/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (2.9.0)\n",
      "Requirement already satisfied: keras_applications>=1.0.6 in /home/aniket/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (1.0.8)\n",
      "Requirement already satisfied: keras_preprocessing>=1.0.5 in /home/aniket/anaconda3/lib/python3.7/site-packages (from keras==2.2.4) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install keras==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqr(var1):\n",
    "    return tf.math.square(var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha = tf.Variable(1.0)\n",
    "beta = tf.Variable(1.0)\n",
    "phi = tf.Variable(1.0)\n",
    "theta = tf.Variable(1.0)\n",
    "gamma = tf.Variable(1.0)\n",
    "r = tf.Variable(1)\n",
    "t = tf.Variable(1)\n",
    "rl = tf.Variable(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = tf.Variable(1/3)\n",
    "c2 = tf.Variable(2/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sin_alpha = tf.math.sin(alpha)\n",
    "sin_two_alpha = tf.math.sin(2*alpha)\n",
    "sin_beta = tf.math.sin(beta)\n",
    "sin_two_beta = tf.math.sin(2*beta)\n",
    "sin_phi = tf.math.sin(phi)\n",
    "sin_two_phi = tf.math.sin(2*phi)\n",
    "sin_theta = tf.math.sin(theta)\n",
    "sin_two_theta = tf.math.sin(2*theta)\n",
    "sin_gamma = tf.math.sin(gamma)\n",
    "sin_phi_beta_subt = tf.math.sin(phi - beta)\n",
    "\n",
    "\n",
    "cos_alpha = tf.math.cos(alpha)\n",
    "cos_beta = tf.math.cos(beta)\n",
    "cos_two_beta = tf.math.cos(2*beta)\n",
    "cos_phi = tf.math.cos(phi)\n",
    "cos_two_phi = tf.math.cos(2*phi)\n",
    "cos_theta = tf.math.cos(theta)\n",
    "cos_gamma = tf.math.cos(gamma)\n",
    "cos_beta_phi_subt = tf.math.cos(beta - phi)\n",
    "cos_beta_theta_add = tf.math.cos(beta + theta)\n",
    "\n",
    "cosec_theta = tf.math.acos(theta)\n",
    "cot_theta = tf.math.atan(theta)\n",
    "cot_alpha = tf.math.atan(alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z1 = sqr(sin_alpha)*sqr(sin_theta)*sqr(cos_beta_phi_subt) + sin_two_theta*sin_alpha*cos_beta_phi_subt - c1\n",
    "\n",
    "Z2 = sqr(sin_alpha)*sqr(cos_theta)*sqr(cos_beta_phi_subt) - sin_alpha*cos_alpha*sin_two_theta*cos_beta_phi_subt + sqr(cos_alpha)*sqr(sin_theta) - c1\n",
    "\n",
    "Z3 = sqr(sin_alpha)*sqr(cosec_theta)*sqr(sin_phi_beta_subt) - c1\n",
    "\n",
    "Z4 = sin_two_theta\n",
    "\n",
    "Z5 = sqr(sin_alpha)*sin_two_phi + sqr(cos_alpha)*sin_two_theta + sin_two_beta*sqr(sin_alpha)*cos_two_phi + sin_two_alpha*cot_theta*(cos_beta*sin_phi + sin_beta*cos_phi)\n",
    "\n",
    "Z6 = sqr(sin_alpha)*cot_theta*(cos_beta*sin_beta*cos_two_phi - sqr(cos_beta)*sin_two_phi) + sqr(sin_alpha)*sin_phi_beta_subt\n",
    "\n",
    "Z7 = sqr(sin_alpha)*(sqr(cos_theta)*sqr(cos_beta_theta_add) + sqr(cos_beta*sin_phi + sin_beta) -sqr(sin_beta)*sqr(sin_phi)  + sqr(cos_alpha)*sqr(sin_theta) - c2  )\n",
    "\n",
    "Z8 = sqr(cos_beta)*sqr(sin_alpha)\n",
    "\n",
    "Z9 = sqr(sin_alpha) * ( sin_beta*cos_beta*(sqr(cosec_theta)*cos_two_phi + cosec_theta*cot_theta + cos_two_phi) + sin_beta*cot_alpha*cot_theta*cos_phi - sin_phi*cos_phi*cos_two_beta*cot_theta*(cot_theta - cosec_theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_net = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(8,)),\n",
    "    tf.keras.layers.Dense(124, activation = tf.nn.relu),\n",
    "    tf.keras.layers.Dense(1, activation = tf.nn.sigmoid)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def u(t, r, alpha, beta, theta, phi, gamma, rl):\n",
    "    u = neural_net([t, r, alpha, beta, theta, phi, gamma, rl], weights, biases)\n",
    "    return u    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(u):\n",
    "    u_t = tf.gradients(u, t)[0]\n",
    "    u_r = tf.gradients(u, r)[0]\n",
    "    u_rr = tf.gradients(u_r, r)[0]\n",
    "    u_sq_rr = tf.gradients(sqr(r)*u_r, r)[0]\n",
    "    \n",
    "    u_th = tf.gradients(u, theta)[0]\n",
    "    u_th = tf.gradients(u_th, theta)[0]\n",
    "    u_th_sin = tf.gradients(tf.math.sin(theta)*u_th, theta)[0]\n",
    "    u_th_r = tf.gradients(u_th, r)[0]\n",
    "    u_th_ph = tf.gradients(u_th, phi)[0]\n",
    "    \n",
    "    u_ph = tf.gradients(u, phi)[0]\n",
    "    u_phph = tf.gradients(u_ph, phi)[0]\n",
    "    u_ph_r = tf.gradients(u_ph, r)[0]\n",
    "    \n",
    "    term1 = (1/sqr(r))*(u_sq_rr)\n",
    "    term2 = (1/sqr(r*sin_theta))*u_th_sin\n",
    "    term3 = (1/sqr(r*sin_theta))*u_phph\n",
    "    del_sqr_spherical = term1 + term2 + term3\n",
    "    \n",
    "    Z = Z1*u_rr + (1/sqr(r))*(Z2*u_thth + Z3*u_phph + Z4*u_th_r - Z5*u_ph_r - Z6*u_th_ph + Z8*u_th + Z9*u_phi)+(1/r)*Z7*u_r\n",
    "    f = u_t - del_sqr_spherical - Z               \n",
    "    return f               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(u):\n",
    "    u_t = tf.gradients(u, t)[0]\n",
    "    u_r = tf.gradients(u, r)[0]\n",
    "    u_rr = tf.gradients(u_r, r)[0]\n",
    "    u_sq_rr = tf.gradients(sqr(r)*u_r, r)[0]\n",
    "    \n",
    "    u_th = tf.gradients(u, theta)[0]\n",
    "    u_th = tf.gradients(u_th, theta)[0]\n",
    "    u_th_sin = tf.gradients(tf.math.sin(theta)*u_th, theta)[0]\n",
    "    u_th_r = tf.gradients(u_th, r)[0]\n",
    "    u_th_ph = tf.gradients(u_th, phi)[0]\n",
    "    \n",
    "    u_ph = tf.gradients(u, phi)[0]\n",
    "    u_phph = tf.gradients(u_ph, phi)[0]\n",
    "    u_ph_r = tf.gradients(u_ph, r)[0]\n",
    "    \n",
    "    term1 = (1/sqr(r))*(u_sq_rr)\n",
    "    term2 = (1/sqr(r*sin_theta))*u_th_sin\n",
    "    term3 = (1/sqr(r*sin_theta))*u_phph\n",
    "    del_sqr_spherical = term1 + term2 + term3\n",
    "    \n",
    "    Z = Z1*u_rr + (1/sqr(r))*(Z2*u_thth + Z3*u_phph + Z4*u_th_r - Z5*u_ph_r - Z6*u_th_ph + Z8*u_th + Z9*u_phi)+(1/r)*Z7*u_r\n",
    "    f = u_t - del_sqr_spherical - Z               \n",
    "    return f               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class model:\n",
    "    \n",
    "    def __init__(self):\n",
    "        xavier=tf.keras.initializers.GlorotUniform()\n",
    "        self.l1=tf.keras.layers.Dense(64,kernel_initializer=xavier,activation=tf.nn.relu,input_shape=[1])\n",
    "        self.l2=tf.keras.layers.Dense(64,kernel_initializer=xavier,activation=tf.nn.relu)\n",
    "        self.out=tf.keras.layers.Dense(1,kernel_initializer=xavier)\n",
    "        self.train_op = tf.keras.optimizers.Adagrad(learning_rate=0.1)\n",
    "        \n",
    "    # Running the model\n",
    "    def run(self,X):\n",
    "        boom=self.l1(X)\n",
    "        boom1=self.l2(boom)\n",
    "        boom2=self.out(boom1)\n",
    "        return boom2\n",
    "      \n",
    "    #Custom loss fucntion\n",
    "    def get_loss(self,X,Y):\n",
    "        boom=self.l1(X)\n",
    "        boom1=self.l2(boom)\n",
    "        boom2=self.out(boom1)\n",
    "        return f(boom2)\n",
    "      \n",
    "    # get gradients\n",
    "    def get_grad(self,X,Y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(self.l1.variables)\n",
    "            tape.watch(self.l2.variables)\n",
    "            tape.watch(self.out.variables)\n",
    "            L = self.get_loss(X,Y)\n",
    "            g = tape.gradient(L, [self.l1.variables[0],self.l1.variables[1],self.l2.variables[0],self.l2.variables[1],self.out.variables[0],self.out.variables[1]])\n",
    "        return g\n",
    "      \n",
    "    # perform gradient descent\n",
    "    def network_learn(self,X,Y):\n",
    "        g = self.get_grad(X,Y)\n",
    "        self.train_op.apply_gradients(zip(g, [self.l1.variables[0],self.l1.variables[1],self.l2.variables[0],self.l2.variables[1],self.out.variables[0],self.out.variables[1]]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(8,1)\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(8, activation=tf.nn.relu, input_shape=input_shape),  # input shape required\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(1,activation=tf.nn.softmax)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = tf.Variable(np.random.normal(size=(1,8,1)), dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    preds = model(inp)\n",
    "\n",
    "grads = tape.gradient(preds, inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array([1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])\n",
    "#inputs = tf.reshape(inputs,[1,8,1])\n",
    "#inputs = tf.Variable(inputs)\n",
    "#inputs = tf.cast(inputs,tf.float32)\n",
    "t = tf.Variable(inputs[0])\n",
    "r = tf.Variable(inputs[1])\n",
    "alpha= tf.Variable(inputs[2])\n",
    "beta= tf.Variable(inputs[3])\n",
    "theta= tf.Variable(inputs[4])\n",
    "phi= tf.Variable(inputs[5])\n",
    "gamma= tf.Variable(inputs[6])\n",
    "rl= tf.Variable(inputs[7])\n",
    "\n",
    "\n",
    "\n",
    "with tf.GradientTape() as tape1:\n",
    "    inp = tf.reshape(tf.stack([t, r, alpha, beta, theta, phi, gamma, rl]),[1,8,1])\n",
    "    inp = tf.cast(inp,tf.float32)\n",
    "    tape1.watch([t, r, alpha, beta, theta, phi, gamma, rl])\n",
    "    preds = model(inp)\n",
    "\n",
    "#print(tape1.gradient(tf.convert_to_tensor(preds), inputs))\n",
    "\n",
    "d_t,d_r,d_al,d_bt,d_th,d_ph,d_gm,d_rl = tape1.gradient(preds, [t, r, alpha, beta, theta, phi, gamma, rl])\n",
    "\n",
    "print (d_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(d_t_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "x_size = [1000,8,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1000, 8, 1]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = tf.random.uniform(shape=x_size, dtype=tf.dtypes.float32, seed=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tf.random.uniform(shape=[num_samples], dtype=tf.dtypes.float32, seed=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tuple(zip(points, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(model, inputs, targets):\n",
    "    inputs = tf.reshape(inputs,[1,8,1])\n",
    "    with tf.GradientTape() as tape2:\n",
    "        with tf.GradientTape() as tape1:\n",
    "            tape1.watch(inputs)\n",
    "            preds = model(inputs)\n",
    "        print(tape1.gradient(tf.convert_to_tensor(preds), inputs))\n",
    "        d_t,d_r,d_al,d_bt,d_th,d_ph,d_gm,d_rl = tape1.gradient(tf.convert_to_tensor(preds), inputs)\n",
    "    d_r_r = tape2.gradient(d_r, r)\n",
    "    d_sq_r_r = tape2.gradient(sqr(r)*d_r, r)\n",
    "    d_th_sin = tape2.gradient(tf.math.sin(theta)*d_th, theta)\n",
    "    d_th_r = tape2.gradient(d_th, r)\n",
    "    d_th_ph = tape2.gradient(d_th, phi)\n",
    "    d_th_th = tape2.gradient(d_th, theta)\n",
    "    d_ph_ph = tape2.gradient(d_ph, phi)\n",
    "    d_ph_r = tape2.gradient(d_ph, r)\n",
    "    term1 = (1/sqr(r))*(d_sq_r_r)\n",
    "    term2 = (1/sqr(r*sin_theta))*d_th_sin\n",
    "    term3 = (1/sqr(r*sin_theta))*d_ph_ph\n",
    "    del_sqr_spherical = term1 + term2 + term3\n",
    "\n",
    "    Z = Z1*u_rr + (1/sqr(r))*(Z2*d_th_th + Z3*d_ph_ph + Z4*d_th_r - Z5*d_ph_r - Z6*d_th_ph + Z8*d_th + Z9*d_phi)+(1/r)*Z7*d_r\n",
    "    loss_value = d_t - del_sqr_spherical - Z  \n",
    "    return loss_value,tape.gradient(loss_value, model.trainable_variables)\n",
    "            \n",
    "            \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.5331018]\n",
      "  [0.5331018]\n",
      "  [0.5331018]\n",
      "  [0.5331018]\n",
      "  [0.5331018]\n",
      "  [0.5331018]\n",
      "  [0.5331018]\n",
      "  [0.5331018]]], shape=(1, 8, 1), dtype=float32)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "GradientTape.gradient can only be called once on non-persistent tapes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-641e0e57887b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Optimize the model1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Track progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-107-a942fb2fe624>\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(model, inputs, targets)\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0md_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_r\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_al\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_bt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_th\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_ph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_gm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_rl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0md_r_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0md_sq_r_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0md_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    964\u001b[0m     \"\"\"\n\u001b[1;32m    965\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m       raise RuntimeError(\"GradientTape.gradient can only be called once on \"\n\u001b[0m\u001b[1;32m    967\u001b[0m                          \"non-persistent tapes.\")\n\u001b[1;32m    968\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recording\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: GradientTape.gradient can only be called once on non-persistent tapes."
     ]
    }
   ],
   "source": [
    "## Note: Rerunning this cell uses the same model variables\n",
    "\n",
    "# Keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 201\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "      epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "      epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "\n",
    "  # Training loop - using batches of 32\n",
    "      for x, y in train_dataset:\n",
    "        # Optimize the model1) \n",
    "        loss_value, grads = grad(model, x, y)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        # Track progress\n",
    "        epoch_loss_avg(loss_value)\n",
    "        \n",
    "        # Add current batch loss\n",
    "        # Compare predicted label to actual label\n",
    "        # training=True is needed only if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        epoch_accuracy(y, model(x, training=True))\n",
    "        \n",
    "        # End epoch\n",
    "        train_loss_results.append(epoch_loss_avg.result())\n",
    "        train_accuracy_results.append(epoch_accuracy.result())\n",
    "\n",
    "        if epoch % 50 == 0:\n",
    "            print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
    "                                                                    epoch_loss_avg.result()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.compile(optimizer = 'adam', loss = custom_loss, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[1,2,3,4,5,6,7,8,9,10]\n",
    "x=np.asarray(x,dtype=np.float32).reshape((10,1))\n",
    "y=[1,4,9,16,25,36,49,64,81,100]\n",
    "y=np.asarray(y,dtype=np.float32).reshape((10,1))\n",
    "model=model()\n",
    "for i in range(100):\n",
    "    model.network_learn(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
